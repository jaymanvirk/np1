{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBRegressor, DMatrix\nfrom sklearn.multioutput import MultiOutputRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom datasets import load_dataset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-19T12:01:03.162557Z","iopub.execute_input":"2024-08-19T12:01:03.162984Z","iopub.status.idle":"2024-08-19T12:01:03.169900Z","shell.execute_reply.started":"2024-08-19T12:01:03.162948Z","shell.execute_reply":"2024-08-19T12:01:03.168569Z"},"trusted":true},"execution_count":284,"outputs":[]},{"cell_type":"code","source":"minds = load_dataset(\"PolyAI/minds14\"\n                     , name=\"en-AU\"\n                     , split=\"train\"\n                     , trust_remote_code=True)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-19T08:18:41.640838Z","iopub.execute_input":"2024-08-19T08:18:41.641297Z","iopub.status.idle":"2024-08-19T08:19:37.982302Z","shell.execute_reply.started":"2024-08-19T08:18:41.641259Z","shell.execute_reply":"2024-08-19T08:19:37.981145Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/471M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c381323ece474b839e68785dd6b3b966"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cb30c5223f24b19ba5c5df88258d8b4"}},"metadata":{}}]},{"cell_type":"code","source":"def get_img_1darray_from_text(text):\n    font = cv2.FONT_HERSHEY_SIMPLEX\n    font_scale = 5\n    color = (255, 255, 255)  # White color\n    thickness = 15\n    # Define text properties\n    (text_width, text_height), baseline = cv2.getTextSize(text, font, font_scale, thickness)\n    img = np.zeros((2*text_height, text_width, 3), dtype=np.uint8)\n\n    position = (0,int(1.5*text_height))\n\n    # Draw the text on the image\n    cv2.putText(img, text, position, font, font_scale, color, thickness, cv2.LINE_AA)\n    \n#     # Display the image using Matplotlib\n#     plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB\n#     plt.axis('off')  # Turn off axis numbers and ticks\n#     plt.show()\n    \n    return np.where(np.all(img == 0, axis=-1), 0, 1).flatten()\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-08-19T12:00:15.797402Z","iopub.execute_input":"2024-08-19T12:00:15.797906Z","iopub.status.idle":"2024-08-19T12:00:15.805968Z","shell.execute_reply.started":"2024-08-19T12:00:15.797870Z","shell.execute_reply":"2024-08-19T12:00:15.804742Z"},"trusted":true},"execution_count":281,"outputs":[]},{"cell_type":"code","source":"data = [get_img_1darray_from_text(minds[\"transcription\"][0])]\n\n# Create DMatrix\ndmatrix = DMatrix(data)","metadata":{"execution":{"iopub.status.busy":"2024-08-19T12:03:41.887416Z","iopub.execute_input":"2024-08-19T12:03:41.887778Z","iopub.status.idle":"2024-08-19T12:03:41.994416Z","shell.execute_reply.started":"2024-08-19T12:03:41.887750Z","shell.execute_reply":"2024-08-19T12:03:41.993488Z"},"trusted":true},"execution_count":294,"outputs":[]},{"cell_type":"code","source":"# Load dataset\nX = data.data\ny = data.target\n\n# Split the dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Q-learning parameters\nnum_episodes = 100\nlearning_rate = 0.1\ndiscount_factor = 0.95\nexploration_prob = 1.0\nexploration_decay = 0.99\nmin_exploration_prob = 0.01\n\n# Define the action space (number of trees, max depth)\nmax_trees = 100\nmax_depth = 10\nactions = [(n_trees, depth) for n_trees in range(1, max_trees + 1, 10) for depth in range(1, max_depth + 1)]\n\n# Initialize Q-table\nQ_table = np.zeros((len(actions),))\n\ndef train_model(n_trees, max_depth):\n    \"\"\"Train XGBoost model and return the RMSE as a negative reward.\"\"\"\n    params = {n_estimators=n_trees\n              , max_depth=max_depth\n              , random_state=42}\n    model = MultiOutputRegressor(XGBRegressor(params))\n    model.fit(X_train, y_train)\n    predictions = model.predict(X_test)\n    rmse = mean_squared_error(y_test, predictions, squared=False)\n    return -rmse  # We want to minimize RMSE\n\n# Q-learning loop\nfor episode in range(num_episodes):\n    state = 0  # Start with the first action\n    if np.random.rand() < exploration_prob:\n        action_index = np.random.choice(len(actions))  # Explore\n    else:\n        action_index = np.argmax(Q_table)  # Exploit\n\n    n_trees, max_depth = actions[action_index]\n    \n    # Train the model and get the reward\n    reward = train_model(n_trees, max_depth)\n    \n    # Update Q-value\n    best_next_action = np.argmax(Q_table)\n    Q_table[action_index] += learning_rate * (reward + discount_factor * Q_table[best_next_action] - Q_table[action_index])\n    \n    # Decay exploration probability\n    exploration_prob = max(min_exploration_prob, exploration_prob * exploration_decay)\n\n    # Print progress\n    if episode % 10 == 0:\n        print(f\"Episode {episode}: Trees={n_trees}, Depth={max_depth}, Reward={reward:.4f}\")\n\n# Find the best hyperparameters\nbest_action_index = np.argmax(Q_table)\nbest_n_trees, best_max_depth = actions[best_action_index]\nprint(f\"Best hyperparameters: Trees={best_n_trees}, Depth={best_max_depth}\")","metadata":{},"execution_count":null,"outputs":[]}]}